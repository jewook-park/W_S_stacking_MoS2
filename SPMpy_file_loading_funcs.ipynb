{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008b366e-acb5-47a2-8f06-a99caf2d2c17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SPMpy file_loding_functions\n",
    "\n",
    "* Authors : Dr. Jewook Park(IBS-CVQS)\n",
    "    * *IBS-CVQS (Inistitute for Basic Science,Center for Van der Waals Quantum Solids), South Korea*\n",
    "    * email :  jewookpark@ibs.re.kr\n",
    "\n",
    "> **SPMpy** is a python package for scanning probe microscopy (SPM) data analysis, such as scanning tunneling microscopy and spectroscopy (STM/S) data and atomic force microscopy (AFM) images, which are inherently multidimensional. To analyze SPM data, SPMpy exploits recent image processing(a.k.a. Computer Vision) techniques. SPMpy data analysis functions utilize well-established Python packages, such as Numpy, PANDAS, matplotlib, Seaborn, holoview, etc. In addition, many parts are inspired by well-known SPM data analysis programs, for example, Wsxm and Gwyddion. Also, SPMpy is applying lessons from 'Fundamentals in Data Visualization'(https://clauswilke.com/dataviz/).\n",
    "\n",
    ">  **SPMpy** is an open-source project. (Github: https://github.com/Jewook-Park/SPMPY )\n",
    "> * Contributions, comments, ideas, and error reports are always welcome. Please use the Github page or email jewookpark@ibs.re.kr. Comments & remarks should be in Korean or English. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ab626-8ef3-411e-a40a-cdcb3d3b5f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <font color=blue>files_in_folder</font>\n",
    "## 0. file path checkup\n",
    "\n",
    "* working folder(path) checkup\n",
    "    * default = current path \n",
    "* files_in_folder(path)\n",
    "    * change the path & show the file list  ( sxm + 3ds)\n",
    "        * to avoid unicodeerror, add 'r' in front of the file path \n",
    "            * eg) path = r'D:\\CALDES data - JEWOOK PARK research group'\n",
    "        * return \n",
    "            * file_list_df columns  = [group,num,file_name,type]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f15ee9f-167a-4fd0-9db6-e268373a7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# check the file location \n",
    "####################################\n",
    "# use the pre-set path \n",
    "# or use get an input \n",
    "#test_path = r'D:\\CALDES data - JEWOOK PARK research group\\CloudStation\\SPMs\\ULT-SPM (Unisoku) - Jewook Park\\Raw data\\2022\\2022 0105 Cu(111) Wtip17 LN2T'\n",
    "#############################\n",
    "# to avoid  \"unicodeescape\" error \n",
    "# add 'r' in front of the file path\n",
    "\n",
    "#files_in_folder = input(\"copy&paste the file location:\")\n",
    "def files_in_folder(path): \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str \n",
    "        folder path \n",
    "        * copy and paste the folder path\n",
    "        * add 'r' to avoid unicodeerror \n",
    "        * eg) test_path = r'D:\\CALDES data - JEWOOK PARK research group\\...'\n",
    "    Returns\n",
    "    -------\n",
    "    file_list_df : PANDAS DataFrame\n",
    "        file list dataframe \n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    currentPath = os.getcwd() #get current path\n",
    "    print (\"Current Path = \", os.getcwd()) # print current path \n",
    "    #######################################\n",
    "    files_in_folder = path\n",
    "    # copy & paste the \"SPM data file\" location (folder(path)) \n",
    "    os.chdir(files_in_folder)\n",
    "    print (\"Changed Path = \", os.getcwd()) \n",
    "    # check the re-located path \n",
    "    ####################################\n",
    "\n",
    "    ######################################\n",
    "    # call all the sxm  files in path    #\n",
    "    ######################################\n",
    "    path = \"./*\"\n",
    "    # pt_spec_file_list = (glob.glob('*.dat')) \n",
    "    sxm_file_list = (glob.glob('*.sxm')) \n",
    "    grid_file_list = (glob.glob('*.3ds')) \n",
    "    csv_file_list = (glob.glob('*.csv')) \n",
    "    gwy_file_list = (glob.glob('*.gwy')) \n",
    "    # using \"glob\"  all \" *.sxm\" files  in file_list\n",
    "    #####################################\n",
    "    ## sxm file\n",
    "    file_list_sxm_df = pd.DataFrame([[\n",
    "        file[:-7],file[-7:-4],file] \n",
    "                                     for file in sxm_file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "\n",
    "    sxm_file_groups= list (set(file_list_sxm_df['group']))\n",
    "    ## 3ds file\n",
    "    file_list_3ds_df = pd.DataFrame([[\n",
    "    file[:-7],file[-7:-4],file] \n",
    "                                 for file in grid_file_list],\n",
    "    columns =['group','num','file_name'])\n",
    "    ## csv file\n",
    "    file_list_csv_df = pd.DataFrame([[\n",
    "        file[:-7],file[-7:-4],file] \n",
    "                                     for file in csv_file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "    ## gwy file\n",
    "    file_list_gwy_df = pd.DataFrame([[\n",
    "        file[:-4], np.nan, file] \n",
    "                                     for file in gwy_file_list],\n",
    "        columns =['group','num','file_name'])   \n",
    "    \n",
    "    file_list_df = pd.concat ([file_list_sxm_df, file_list_3ds_df, file_list_csv_df, file_list_gwy_df],ignore_index= True)\n",
    "    file_list_df['type'] = [file_name[-3:] for file_name in  file_list_df.file_name]\n",
    "    print (file_list_df)\n",
    "\n",
    "    \n",
    "    #############################################################\n",
    "    # to call all the files in sxm_file_groups[0]\n",
    "    ##  file_list_df[file_list_df['group'] == sxm_file_groups[0]]\n",
    "    #############################################################\n",
    "    #print (file_list_sxm_df)\n",
    "    #print (file_list_3ds_df)\n",
    "    # indicates # of files in each group \n",
    "    for group in sxm_file_groups:\n",
    "        print ('sxm file groups :  ', group, ':  # of files = ',\n",
    "               len(file_list_sxm_df[file_list_sxm_df['group'] == group]) )\n",
    "    if len(file_list_df[file_list_df['type'] == '3ds']) ==0 :\n",
    "        print ('No GridSpectroscopy data')\n",
    "    else :\n",
    "        print ('# of GridSpectroscopy',\n",
    "               list(set(file_list_df[file_list_df['type'] == '3ds'].group))[0], \n",
    "               ' = ',           \n",
    "               file_list_df[file_list_df['type'] == '3ds'].group.count())\n",
    "\n",
    "    return file_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3375c309-b3ca-42ad-b0e2-5fc9ccab8ad1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <font color=blue>img2xr</font>\n",
    "## 1. 2D image (topography & LDOS, *.sxm) to xarray  \n",
    "\n",
    "* input: nanonis 2D data (*.sxm) \n",
    "* output : Xarray (_xr) with attributes\n",
    "    * nanonis (sxm)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) \n",
    "* Xarray attributes\n",
    "        * title\n",
    "        * X_spacing\n",
    "        * Y_spacing\n",
    "        * freq_X_spacing\n",
    "        * freq_Y_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2b14ac-ef18-4e92-b4fc-5a5b8e82a355",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "I91tRQmWf3Ry",
    "lines_to_next_cell": 2,
    "outputId": "4d722d2c-3419-45a1-cc42-c9ab6d7ca18d"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# conver the given sxm file in current path\n",
    "# to  xarray DataSet (including attributes)\n",
    "\n",
    "def img2xr (loading_sxm_file, center_offset = False):\n",
    "    # import necessary module \n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import math\n",
    "    import matplotlib.pyplot as plt\n",
    "    import re\n",
    "\n",
    "    from warnings import warn\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        !pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        !pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        !pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "\n",
    "    ####################################\n",
    "    # check the file location \n",
    "    ####################################\n",
    "    currentPath = os.getcwd() #get current path\n",
    "    print (os.getcwd()) # print current path \n",
    "    file_list = (glob.glob('*.sxm')) \n",
    "    file_list_df = pd.DataFrame(\n",
    "        [[file[:-7],file[-7:-4],file] for file in file_list],\n",
    "        columns =['group','num','file_name'])\n",
    "    # check all the sxm files in the folder \n",
    "    if file_list_df.file_name.isin([loading_sxm_file]).sum() == 0: \n",
    "        print ('no sxm file')\n",
    "    else : \n",
    "        print(file_list_df[file_list_df.file_name == loading_sxm_file])\n",
    "    #######################################\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(loading_sxm_file)\n",
    "    Scan = nap.read.Scan(NF.fname)\n",
    "    #Scan.basename # file name only *.sxm \n",
    "    #Scan.header # heater dict \n",
    "    ##############################\n",
    "    # Scan conditions from the header\n",
    "    V_b = float(Scan.header['bias>bias (v)'])\n",
    "    I_t = float(Scan.header['z-controller>setpoint'])\n",
    "\n",
    "    [size_x,size_y] = Scan.header['scan_range']\n",
    "    [cntr_x, cntr_y] = Scan.header['scan_offset']\n",
    "    [dim_px,dim_py] = Scan.header['scan_pixels']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size # size를 pixel로 나눔\n",
    "    Rot_Rad = math.radians( float(Scan.header['scan_angle'])) \n",
    "    #str --> degree to radian \n",
    "\n",
    "    print ('scan direction (up/down): ', Scan.header['scan_dir'])\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])\n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])\n",
    "    # nX,nY for meshgrid (start from 1/2, not 0 )\n",
    "    # dimesion맞춘 x, y steps # i 가 0부터 시작하니 1/2 더했음\n",
    "    # In case of rotation ==0\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    # center position  과 scan size을 고려한 x,y real \n",
    "    #########################################################################\n",
    "    # np.meshgrid \n",
    "    x_mesh_0, y_mesh_0 = np.meshgrid(nX, nY)\n",
    "    x_mesh = cntr_x - size_x + x_mesh_0\n",
    "    y_mesh = cntr_y - size_y + y_mesh_0 \n",
    "    # if there is rotation \n",
    "    x_mesh_r   =  np.cos(Rot_Rad)*x_mesh_0 + np.sin(Rot_Rad)*y_mesh_0  # \"cloclwise\"\n",
    "    y_mesh_r   = -np.sin(Rot_Rad)*x_mesh_0 + np.cos(Rot_Rad)*y_mesh_0\n",
    "    #########################################################################\n",
    "    # image title \n",
    "    # image가 rotation되었을 경우는 따로 표시 rot !=0 \n",
    "    if Rot_Rad ==0 : \n",
    "        image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                    ' V = '+ str(V_b) + ' V ' +\\\n",
    "                        ' I = ' + str(round(I_t *1E12)) + ' pA ' \n",
    "    else: \n",
    "        image_title = Scan.basename[:-4] + '\\n' + \\\n",
    "            str(round(size_x* 1E9 )) + ' nm x ' + \\\n",
    "                str(round(size_y* 1E9 )) + ' nm '  +\\\n",
    "                    ' V = '+ str(V_b) + ' V ' +\\\n",
    "                        ' I = ' + str(round(I_t *1E12)) + ' pA ' +\\\n",
    "                            ' R = ' + str(math.degrees(Rot_Rad)) + 'deg'\n",
    "    print(image_title)\n",
    "    #########################################################################\n",
    "    # scan channels in DataFrame\n",
    "\n",
    "    #Scan.signals.keys()\n",
    "    Scan.signals['Z'].keys()\n",
    "    \n",
    "    Scan.signals['Z']['forward'].shape\n",
    "    z_fwd = Scan.signals['Z']['forward']\n",
    "    z_bwd = Scan.signals['Z']['backward'][:,::-1]\n",
    "\n",
    "    \n",
    "    #Scan.signals['LI_Demod_1_X'].keys()\n",
    "    \n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_key = [s  for s in Scan.signals.keys()  if \"LIX\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd  = Scan.signals[LIX_key[0]]['forward']\n",
    "    LIX_bwd  = Scan.signals[LIX_key[0]]['backward'][:,::-1]\n",
    "\n",
    "    #LIX_fwd = Scan.signals['LI_Demod_1_X']['forward']\n",
    "    #LIX_bwd = Scan.signals['LI_Demod_1_X']['backward'][:,::-1]\n",
    "    # LIX channel name varies w.r.t nanonis version \n",
    "    \n",
    "    # same for LIY --> update later.. if needed \n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    #LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    #LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "     \n",
    "    \n",
    "    \n",
    "    #bwd channel : opposite data direction. \n",
    "    #bwd 는 x방향 순서가 반대다.  # 뒤집어 줘야 함. \n",
    "    ########################################\n",
    "    if Scan.header['scan_dir'] == 'down':\n",
    "        z_fwd = z_fwd[::-1,:]\n",
    "        z_bwd = z_bwd[::-1,:]\n",
    "        LIX_fwd = LIX_fwd[::-1,:]\n",
    "        LIX_bwd = LIX_bwd[::-1,:]\n",
    "    # if scan_direction == down, flip the data\n",
    "    #scan 방향이 down 이면 y 방향 아래위 뒤집어준다\n",
    "    ########################################\n",
    "    z_fwd_df = pd.DataFrame(z_fwd)\n",
    "    z_fwd_df.index.name ='row_y'\n",
    "    z_fwd_df.columns.name ='col_x'\n",
    "\n",
    "    z_bwd_df = pd.DataFrame(z_bwd)\n",
    "    z_bwd_df.index.name ='row_y'\n",
    "    z_bwd_df.columns.name ='col_x'\n",
    "\n",
    "    LIX_fwd_df = pd.DataFrame(LIX_fwd)\n",
    "    LIX_fwd_df.index.name ='row_y'\n",
    "    LIX_fwd_df.columns.name ='col_x'\n",
    "\n",
    "    LIX_bwd_df = pd.DataFrame(LIX_bwd)\n",
    "    LIX_bwd_df.index.name ='row_y'\n",
    "    LIX_bwd_df.columns.name ='col_x'\n",
    "    # save data channels as DataFrame\n",
    "    # z & LIX 를 df 로 저장 \n",
    "    ########################################\n",
    "    z_fwd_df = z_fwd_df.fillna(0)\n",
    "    z_bwd_df = z_bwd_df.fillna(0)\n",
    "    LIX_fwd_df = LIX_fwd_df.fillna(0)   \n",
    "    LIX_bwd_df = LIX_bwd_df.fillna(0)\n",
    "    # incompleted scan ==> np.nan in data point, ==> fillna()\n",
    "    # scan 방향이 중간에 멈추었다면, 0 으로채운다.\n",
    "    ########################################\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # conver to DataFrame (PANDAS) \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    z_LIX_fNb_df = pd.concat([z_fwd_df.stack(),\n",
    "                              z_bwd_df.stack(),\n",
    "                              LIX_fwd_df.stack(),\n",
    "                              LIX_bwd_df.stack()], axis = 1)\n",
    "    # set colunm name for new DataFrame\n",
    "    z_LIX_fNb_df.columns =['z_fwd','z_bwd', 'LIX_fwd','LIX_bwd']\n",
    "    # z_LIX_fNb_df\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # conver to xarray \n",
    "    ############################\n",
    "    z_LIX_fNb_xr = z_LIX_fNb_df.to_xarray()\n",
    "    # rename coord as \"X\", \"Y\" \n",
    "    z_LIX_fNb_xr = z_LIX_fNb_xr.rename(\n",
    "        {\"row_y\": \"Y\", \"col_x\":\"X\"})\n",
    "    # real size of XY \n",
    "    z_LIX_fNb_xr= z_LIX_fNb_xr.assign_coords(\n",
    "        X = z_LIX_fNb_xr.X.values *step_dx, \n",
    "        Y = z_LIX_fNb_xr.Y.values *step_dy )\n",
    "    # XY axis: 0 ~ size_XY\n",
    "\n",
    "    ############################\n",
    "    # check the XY ratio \n",
    "    ############################\n",
    "    if  size_x == size_y : \n",
    "        pass\n",
    "    else : \n",
    "        print ('size_x != size_y')\n",
    "    # if xy size is not same, report it! \n",
    "\n",
    "    if step_dx != step_dy :\n",
    "        xystep_ratio = step_dy/step_dx # check the XY pixel_ratio\n",
    "        X_interp = np.linspace(\n",
    "        z_LIX_fNb_xr.X[0], z_LIX_fNb_xr.X[-1], z_LIX_fNb_xr.X.shape[0]*1)\n",
    "        step_dx = step_dx # step_dx check \n",
    "\n",
    "        Y_interp = np.linspace(\n",
    "        z_LIX_fNb_xr.Y[0], z_LIX_fNb_xr.Y[-1], int(z_LIX_fNb_xr.Y.shape[0]*xystep_ratio)) \n",
    "        step_dy = step_dy/ xystep_ratio # step_dy check \n",
    "\n",
    "        # interpolation ratio should be int\n",
    "        z_LIX_fNb_xr= z_LIX_fNb_xr.interp(X = X_interp, Y = Y_interp)\n",
    "        print('step_dx/step_dy = ', xystep_ratio)\n",
    "        print ('z_LIX_fNb_xr ==> reshaped')\n",
    "    else: \n",
    "        z_LIX_fNb_xr =z_LIX_fNb_xr\n",
    "        print('step_dx == step_dy')\n",
    "    #print('z_LIX_fNb_xr', 'step_dx, step_dy = ',  z_LIX_fNb_xr.dims)\n",
    "    print('z_LIX_fNb_xr', 'step_dx, step_dy = ', \n",
    "          re.findall('\\{([^}]+)', str(z_LIX_fNb_xr.dims)))\n",
    "    # regex practice\n",
    "\n",
    "\n",
    "    ##########\n",
    "    #################################\n",
    "    # assigne attributes \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    z_LIX_fNb_xr.attrs['title'] = image_title\n",
    "    if 'Wtip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'W'\n",
    "    elif 'Ni_tip' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Ni'\n",
    "    elif 'Co_coated' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'Co_coated'\n",
    "    elif 'AFM' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'AFM'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['tip'] = 'To Be Announced'\n",
    "        print('tip material will be announced')\n",
    "        \n",
    "    if 'Cu(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Cu(111)'\n",
    "    elif 'Au(111)' in image_title:\n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'Au(111)'\n",
    "    else: \n",
    "        z_LIX_fNb_xr.attrs['sample'] = 'To Be Announced'\n",
    "        print('sample type will be announced')\n",
    "    \n",
    "    z_LIX_fNb_xr.attrs['image_size'] = [size_x,size_y]\n",
    "    z_LIX_fNb_xr.attrs['X_spacing'] = step_dx\n",
    "    z_LIX_fNb_xr.attrs['Y_spacing'] = step_dy    \n",
    "    z_LIX_fNb_xr.attrs['freq_X_spacing'] = 1/step_dx\n",
    "    z_LIX_fNb_xr.attrs['freq_Y_spacing'] = 1/step_dy\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        z_LIX_fNb_xr.assign_coords(X=(z_LIX_fNb_xr.X + cntr_x -  size_x/2))\n",
    "        z_LIX_fNb_xr.assign_coords(Y=(z_LIX_fNb_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "\n",
    "\n",
    "    #################################\n",
    "    # test & how to use xr data \n",
    "    # z_LIX_fNb_xr  # xr dataset (with data array channels )\n",
    "    #z_LIX_fNb_xr.z_fwd # select data channel\n",
    "    #z_LIX_fNb_xr.data_vars # data channels check \n",
    "    #z_LIX_fNb_xr.z_fwd.values  # to call data array in nd array \n",
    "    #z_LIX_fNb_xr.dims # data channel dimension (coords) \n",
    "    #z_LIX_fNb_xr.coords # data  channel coordinates check \n",
    "    #z_LIX_fNb_xr.attrs # data  channel attributes check \n",
    "\n",
    "    return z_LIX_fNb_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f281e",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "source": [
    "# <font color=blue>grid2xr</font>\n",
    "## 2.  GridSpectroscopy (*.3ds)  to xarray  \n",
    "\n",
    "* input: *.3ds file  ( grid 3d dataset )\n",
    "* output: Xarray (_xr) with attributes\n",
    "    * nanonis 3D data set (3ds)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) \n",
    "* Xarray attributes\n",
    "    * title\n",
    "    * X_spacing\n",
    "    * Y_spacing\n",
    "    * bias mV info\n",
    "    * freq_X_spacing\n",
    "    * freq_Y_spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0258a2-24b6-4ee9-8683-5d666baa8b51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#griddata_file = file_list_df[file_list_df.type=='3ds'].iloc[0].file_name\n",
    "\n",
    "def grid2xr(griddata_file, center_offset = True): \n",
    "\n",
    "    file = griddata_file\n",
    "    #####################\n",
    "    # conver the given 3ds file\n",
    "    # to  xarray DataSet (check the attributes)\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import numpy.fft as npf\n",
    "    #import xarray as xr\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        !pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        !pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        !pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "    try:\n",
    "        import xrft\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xrft')\n",
    "        !pip install xrft \n",
    "        import xrft\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(file)\n",
    "    Gr = nap.read.Grid(NF.fname)#\n",
    "    ## Gr 로  해당 grid data 불러옴 # 중간에 끊기면 안됨\n",
    "    channel_name = Gr.signals.keys()  # Gr 내의 data signals\n",
    "    #print (channel_name)\n",
    "    N = len(file);\n",
    "    f_name = file[0:N-4]\n",
    "    print (f_name) # Gr.basename\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    #Header part\n",
    "    #####################################\n",
    "    #  Gr.header\n",
    "    #####################################\n",
    "    [dim_px,dim_py] = Gr.header['dim_px'] \n",
    "    [cntr_x, cntr_y] = Gr.header['pos_xy']\n",
    "    [size_x,size_y] = Gr.header['size_xy']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size # size를 pixel로 나눔\n",
    "\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])# dimesion맞춘 xstep \n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])# dimesion맞춘 ystep \n",
    "\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    # center position  과 scan size을 고려한 x,y real \n",
    "    #####################################\n",
    "    # signal part\n",
    "    # Gr.signals\n",
    "    #####################################\n",
    "    topography = Gr.signals['topo']\n",
    "    params_v = Gr.signals['params'] \n",
    "    # params_v.shape = (dim_px,dim_py,15) \n",
    "    # 15: 3ds infos. \n",
    "    bias = Gr.signals['sweep_signal']\n",
    "    # check the shape (# of 'original' bias points)\n",
    "    I_fwd = Gr.signals['Current (A)'] # 3d set (dim_px,dim_py,bias)\n",
    "    I_bwd = Gr.signals['Current [bwd] (A)'] # I bwd\n",
    "    # sometimes, LI channel names are inconsistent depends on program ver. \n",
    "    # find 'LI Demod 1 X (A)'  or  'LI X 1 omega (A)'\n",
    "\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd, LIX_bwd = Gr.signals[LIX_keys[0]] ,Gr.signals[LIX_keys[1] ]\n",
    "\n",
    "    # same for LIY\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #plt.imshow(topography) # toppography check\n",
    "    #plt.imshow(I_fwd[:,:,0]) # LIX  check\n",
    "    ###########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    #\t\t Grid data 에 대한 Title 지정 \n",
    "    #       grid size, pixel, bias condition 포함 #\n",
    "    #############################################################\n",
    "    # Gr.header.get('Bias>Bias (V)') # bias condition \n",
    "    # Gr.header.get('Z-Controller>Setpoint') # current set  condition\n",
    "    # Gr.header.get('dim_px')  # jpixel dimension \n",
    "    title = Gr.basename +' ('  + str(\n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep Start (V)'))\n",
    "    ) +' V ~ ' +str( \n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep End (V)'))\n",
    "    )+ ' V) \\n at Bias = '+ Gr.header.get(\n",
    "        'Bias>Bias (V)'\n",
    "    )[0:-3]+' mV, I_t =  ' + Gr.header.get(\n",
    "        'Z-Controller>Setpoint'\n",
    "    )[0:-4]+ ' pA, '+str(\n",
    "        Gr.header.get('dim_px')[0]\n",
    "    )+' x '+str(\n",
    "        Gr.header.get('dim_px')[1]\n",
    "    )+' points'\n",
    "    #############################################################       \n",
    "\n",
    "    ### some times the topography does not look right. \n",
    "    # * then use the reshaping function \n",
    "    # only for asymmetry grid data set\n",
    "\n",
    "    # eg) JW's MoS2 on HOPG exp. data \n",
    "\n",
    "    ###########################################################\n",
    "    # topography  를 topography_reshape 으로 재지정.  \n",
    "    ###########################################################\n",
    "    topo_dimension_true = True\n",
    "\n",
    "\n",
    "    if topo_dimension_true == True:\n",
    "        topography_reshape = topography   \n",
    "        #################################\n",
    "        I_fwd_copy = I_fwd\n",
    "        I_bwd_copy = I_bwd\n",
    "        LIX_fwd_copy = LIX_fwd \n",
    "        LIX_bwd_copy = LIX_bwd \t\n",
    "        # topography가 정상인 경우    \n",
    "        #################################\n",
    "\n",
    "        ##########################################################\n",
    "        # 예를 들어  #  MoS2 on HOPG image 는 \n",
    "        # 40 x 80 의 배열이 40x40 + 40 x40으로 되었음. \n",
    "        # x 한줄이 0-39: 1st line 40-79 : 2nd line임\n",
    "        # 0-40, 19-59, 39-79 가 set로 움직임. \n",
    "        # 세로로 40X80 배열을 만들어서 \n",
    "        # 0-39 를 2n으로 40-79 를 2n+1 으로 대입할것. \n",
    "        # topo # LIX f&b # I f&b #\n",
    "        ##########################################################\n",
    "\n",
    "    else: # topography가 비 정상인 경우  \n",
    "        # topo_dimension_true == False 일경우 \n",
    "        topography_reshape = np.transpose(np.copy(topography),(1,0)) \n",
    "        # 바꾼 dimension이 될 곳을 미리 만듬. \n",
    "        for x_indx, y_indx in enumerate (topography):\n",
    "        # print(x_indx) # 0-39 # print(y_indx.shape)\n",
    "            topography_reshape[2*x_indx,:] = y_indx[:40] # 앞쪽 절반은 첫번째줄로\n",
    "            topography_reshape[2*x_indx+1,:] = y_indx[40:80] # 뒷쪽 절반은 두번째 줄로  \n",
    "        #################################\n",
    "        # 새로 바꾸는 정렬 방법을 확인하여 같은방식으로 I, LIX 에도 적용\n",
    "        #################################\n",
    "        #제대로 붙었는지 테스트\n",
    "        plt.imshow(topography_reshape) # 80 * 40 OK\n",
    "        # topography_reshape 정렬 끝 \n",
    "        #################################\n",
    "        I_fwd_copy = np.transpose(np.copy(I_fwd),(1,0,2))\n",
    "        I_bwd_copy = np.transpose(np.copy(I_bwd),(1,0,2)) \n",
    "        # 바꾼 dimension이 될 곳을 미리 만듬. \t\n",
    "        for x_indx, yNbias_plane in enumerate (I_fwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            print(x_indx) # 0-39 \n",
    "            I_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            I_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로  \n",
    "\n",
    "        for x_indx, yNbias_plane in enumerate (I_bwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            print(x_indx) # 0-39 \n",
    "            I_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            I_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로plt.imshow(I_bwd_v[:,:,0]) # 40 * 256  cut \n",
    "        #################################\n",
    "        # I reshape is done \n",
    "        #################################\n",
    "        LIX_fwd_copy = np.transpose(np.copy(LIX_fwd),(1,0,2)) \n",
    "        LIX_bwd_copy = np.transpose(np.copy(LIX_bwd),(1,0,2)) \n",
    "        # 바꾼 dimension이 될 곳을 미리 만듬. \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_fwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            LIX_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            LIX_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로  \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_bwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            LIX_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            LIX_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로\n",
    "        #################################\n",
    "        # LIX reshape is done \n",
    "        #################################\n",
    "    #제대로 붙었는지 테스트\n",
    "\n",
    "    #fig,axes = plt.subplots (nrows = 2,ncols = 3, figsize = (5,4),\n",
    "    #                         sharex=True, sharey=True)\n",
    "    #axs = axes.ravel()\n",
    "    #axs[0].imshow(topography)\n",
    "    #axs[0].set_title('topography')\n",
    "\n",
    "    #axs[1].imshow(I_fwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[1].set_title('I_fwd[0]')\n",
    "    #axs[2].imshow(LIX_fwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[2].set_title('LIX_fwd[0]')\n",
    "\n",
    "    #axs[3].imshow(topography_reshape)\n",
    "    #axs[3].set_title('topo_reshape')\n",
    "\n",
    "    #axs[4].imshow(I_bwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[4].set_title('I_bwd[0]')\n",
    "\n",
    "    #axs[5].imshow(LIX_bwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[5].set_title('LIX_bwd[0]')\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # after reshaping \n",
    "\n",
    "    topography = topography_reshape \n",
    "    #################################\n",
    "    I_fwd = I_fwd_copy \n",
    "    I_bwd = I_bwd_copy \n",
    "    LIX_fwd  = LIX_fwd_copy \n",
    "    LIX_bwd  = LIX_bwd_copy\n",
    "    ##########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # Bias segment check      #\n",
    "    ###########################\n",
    "    Segment = Gr.header['Bias>Bias (V)']\n",
    "    # bias unit : '(V)' \n",
    "\n",
    "    if type(Segment) == str: # single segment case\n",
    "        print ('No Segments\\n'+ 'Grid data acquired at bias = '+  str(float(Segment)) + 'V')    \n",
    "    ## No Segments # +  bias setting \n",
    "\n",
    "    ########################\n",
    "    # bias interpolation to have bias \n",
    "    # bias_mV 는 bias 를 0 포함한 값으로interploation \n",
    "    # 3D data 가운데 x,y 를 꺼내서 bias interpolation \n",
    "    # e.g  256--> 양 끝점을 포함한 256+1 으로. (center 가 0가 되도록 )\n",
    "        if len(bias)%2==0:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias)+1)) \n",
    "            # 시작 부터 끝까지, 0포함 홀수, 전체크기+1 개의 단계로 세분화\n",
    "        else:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias))) \n",
    "            # bias_new  는 간격이 홀수개가 되도록 나눈 것임, 즉 0에가장 가까운 값이 하나뿐이도록 조정함 \n",
    "        #새로 만든 bias_new 안에 있는지 없는지를 찾는다. \n",
    "        # '''    if np.amin(abs(bias_new)) < 1E-3: \n",
    "        ## 즉 0 이 아닌 값이 나오는 경우 이부분이 if가 필요한지 의문 ''' \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # 0  에 가장가까운 값이 나온 곳의 index 를 찾음 \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # 가장 0에 가까운 값을 0으로 옮겼으니 항상 0 를 포함함. \n",
    "        #bias_new[np.where(bias_new == np.amin(abs(bias_new)))]=0\n",
    "\n",
    "    ##############################################\n",
    "    #'Segment Start (V), Segment End (V), Settling (s), Integration (s), Steps (xn)'\n",
    "    elif len(Segment) == 3:\n",
    "        print('Number of Segments =' + str(len(Segment))) \n",
    "        Segments = np.array([[ float(Segments) \n",
    "                              for Segments in Seg.split(',') ] \n",
    "                             for Seg in Segment], dtype = np.float64)\n",
    "        #  Segment 에서 한줄 씰 꺼내서, array, 한줄씩\n",
    "        #','로 split한 문자들을 하나씩 float 변수로 바꿈, & np array화\n",
    "        ### 현재 Nanonis version에서 bias 는 정확한 값이 아님. \n",
    "        Seg1 = np.linspace(Segments[0,0],Segments[0,1],int(Segments[0,-1]))\n",
    "        Seg2 = np.linspace(Segments[1,0],Segments[1,1],int(Segments[1,-1]))\n",
    "        Seg3 = np.linspace(Segments[2,0],Segments[2,1],int(Segments[2,-1]))\n",
    "        # 겹치는  boundary 제외하고([1:]), Seg1, Seg2[1:], Seg3[1:] 합친다. \n",
    "        bias_Seg = np.append(np.append(Seg1,Seg2[1:]),Seg3[1:]) \n",
    "        # Seg1 에 Seg2[1:] 더하고, 거기에 다시한번 Se3[1:] 더함\n",
    "        print ('bias_Seg size = ' + str(len(bias_Seg)))\n",
    "        bias_Nsteps=int(int(Segments[1,-1])/\n",
    "                        (Seg2[-1]-Seg2[0])*(bias_Seg[-1]-bias_Seg[0]))\n",
    "        # 새로운 bias step 은 가장 작은 step size를 전체 영역에 적용함.    \n",
    "        bias_Nsteps_size = (Seg2[-1]-Seg2[0])/(Segments[1,-1])\n",
    "        # (Segments[1,0]-Segments[1,1])/int(Segments[1,-1]) # bias step size    \n",
    "        Neg_bias=-1*np.arange(\n",
    "            0,bias_Nsteps_size*bias_Nsteps/2, bias_Nsteps_size)\n",
    "        Pos_bias=np.flip(\n",
    "            np.arange(0,bias_Nsteps_size*bias_Nsteps/2,bias_Nsteps_size))\n",
    "        bias_new = np.flip( np.append(Pos_bias,Neg_bias[1:])) \n",
    "        # segment 이후 bias 는 bias_new 로 재조립되었음\t\n",
    "        #여기에서 bias_new 를 홀수로 변환\n",
    "        if len(bias_new)%2==0:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new)+1)) \n",
    "        else:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new))) \n",
    "        # 여기서 다시 bias_new가 0를 포함하는 확인해야함. \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # 0  에 가장가까운 값이 나온 곳의 index 를 찾음 \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # 시작 부터 끝까지, 0포함 홀수\n",
    "        print ('bias_new size = ' + str(len(bias_new)))\n",
    "        # bias \n",
    "    # make a new list for Bias\n",
    "    else:\n",
    "        print (\"Segment error /n code a 5 Sements case\")\n",
    "    #\n",
    "    ######################################################################\n",
    "    # Segment가 있더라도 모두 \n",
    "    # 0을 포함한 홀수개의 같은 간격을 갖는  bias_new 로 bias 축을 바꿨음. \n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # bias_new 를 이용해서 interpolation\n",
    "    # I_fwd, I_bwd, LIX_fwd, LIX_bwd\n",
    "    # => I_fwd_interpolate\n",
    "    #######################################################################\n",
    "\n",
    "    def sweep_interpolation(np3Ddata, bias, bias_new):\n",
    "        np3Ddata_interpolate = np.empty(\n",
    "                    (np3Ddata.shape[0],np3Ddata.shape[1],bias_new.shape[0])) \n",
    "        # 원래값과 같지만, bias_new의 형태를 갖춘 empty interpolate 영역 만들고\n",
    "        #xy dim 은 그대로 z 는 new bias dim으로        \n",
    "        for x_i,np3Ddata_xi in enumerate(np3Ddata):\n",
    "            for y_j,np3Ddata_xi_yj in enumerate(np3Ddata_xi):\n",
    "                #print (np3Ddata_xi_yj.shape)\n",
    "                Interpolation1D_i_f = sp.interpolate.interp1d(\n",
    "                    bias,\n",
    "                    np3Ddata_xi_yj,\n",
    "                    fill_value = \"extrapolate\",\n",
    "                    kind = 'cubic')\n",
    "                np3Ddata_interpolate[x_i,y_j,:] = Interpolation1D_i_f(bias_new)\n",
    "        return np3Ddata_interpolate\n",
    "\n",
    "    I_fwd_interpolate = sweep_interpolation (I_fwd, bias, bias_new)\n",
    "    I_bwd_interpolate = sweep_interpolation (I_bwd, bias, bias_new)\n",
    "    LIX_fwd_interpolate = sweep_interpolation (LIX_fwd, bias, bias_new)\n",
    "    LIX_bwd_interpolate = sweep_interpolation (LIX_bwd, bias, bias_new)\n",
    "\n",
    "    ####################################################\n",
    "    # interpolation 값과 bias_new 를 \n",
    "    #\n",
    "    # bias 방향 바꿈 그림 그릴때 헷갈리지 않도록. \n",
    "    ###################################################\n",
    "    # Bias원래 방향에 맞춰서 둘중하나 선택 \n",
    "    ###################################################\n",
    "    if bias[0]>bias[-1]: \n",
    "        # 시작점이 마지막점보다 크면 (양수에서시작)\n",
    "        # 변하는 것 없음. \t\n",
    "        print ('start from POS bias')\n",
    "        I_fwd = I_fwd_interpolate\n",
    "        I_bwd = I_bwd_interpolate\n",
    "        LIX_fwd = LIX_fwd_interpolate\n",
    "        LIX_bwd = LIX_bwd_interpolate\n",
    "        bias_mV = bias_new*1000\n",
    "    else:  # 시작점이 마지막점보다 작으면 (음수에서시작)\n",
    "        print ('start from NEG bias')\n",
    "        I_fwd = np.flip(I_fwd_interpolate,2)\n",
    "        I_bwd = np.flip(I_bwd_interpolate,2)\n",
    "        LIX_fwd = np.flip(LIX_fwd_interpolate,2)\n",
    "        LIX_bwd = np.flip(LIX_bwd_interpolate,2)\n",
    "        bias_new_flip = np.flip(bias_new)\n",
    "        # bias 0 는 POS , bias last 는 NEG bias로 바꿈. \n",
    "        bias_mV = bias_new_flip*1000\n",
    "        print ('Flip => start from POS bias')\n",
    "    ####################################################\n",
    "\n",
    "    ###################################################\n",
    "    # convert data XR DataSEt\n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "    # col = x \n",
    "    # row = y\n",
    "    # I_fwd grid data ==> [Y, X, bias 로 대입]\n",
    "    grid_xr = xr.Dataset(\n",
    "        {\n",
    "            \"I_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_fwd),\n",
    "            \"I_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_bwd),\n",
    "            \"LIX_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_fwd),\n",
    "            \"LIX_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_bwd),\n",
    "            \"topography\" : ([\"Y\",\"X\"], topography)\n",
    "        },\n",
    "        coords = {\n",
    "            \"X\": ([\"X\"], x),\n",
    "            \"Y\": ([\"Y\"], y),\n",
    "            \"bias_mV\": ([\"bias_mV\"], bias_mV)\n",
    "        }\n",
    "    )\n",
    "    grid_xr.attrs[\"title\"] = title\n",
    "    #grid_xr.attrs['image_size'] = \n",
    "    #grid_xr.attrs['samlpe'] = \n",
    "    \n",
    "    grid_xr.attrs['image_size']= [size_x,size_y]\n",
    "    grid_xr.attrs['X_spacing']= step_dx\n",
    "    grid_xr.attrs['Y_spacing']= step_dy    \n",
    "    grid_xr.attrs['freq_X_spacing']= 1/step_dx\n",
    "    grid_xr.attrs['freq_Y_spacing']= 1/step_dy\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        grid_xr.assign_coords( X = (grid_xr.X + cntr_x -  size_x/2))\n",
    "        grid_xr.assign_coords( Y = (grid_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "    \n",
    "    \n",
    "    \n",
    "    return grid_xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d064ae4-7023-4db9-b963-4a03197dbe3b",
   "metadata": {},
   "source": [
    "# <font color=blue>grid_line2xr</font>\n",
    "## 3.  Line Spectroscopy (*.3ds)  to xarray  \n",
    "\n",
    "* input: *.3ds file (Line spectroscopy) \n",
    "* output: Xarray (_xr) with attributes\n",
    "    * nanonis 3D data set (3ds)  $\\to $ numpy $\\to$ pd.DataFrame(_df) $\\to$ xr.DataSet (_xr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f559acd-2207-4766-aa10-b24150aab860",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#griddata_file = file_list_df[file_list_df.type=='3ds'].iloc[0].file_name\n",
    "\n",
    "def grid_line2xr(griddata_file, center_offset = True): \n",
    "\n",
    "    file = griddata_file\n",
    "    #####################\n",
    "    # conver the given 3ds file\n",
    "    # to  xarray DataSet (check the attributes)\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import numpy.fft as npf\n",
    "    #import xarray as xr\n",
    "    import pandas as pd\n",
    "    import scipy as sp\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    try:\n",
    "        import nanonispy as nap\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named nanonispy')\n",
    "        !pip install nanonispy\n",
    "        import nanonispy as nap\n",
    "\n",
    "    try:\n",
    "        import xarray as xr\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xarray')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        !pip install xarray \n",
    "        import xarray as xr\n",
    "\n",
    "    try:\n",
    "        import seaborn_image as isns\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named seaborn-image')\n",
    "        #!pip install --upgrade scikit-image == 0.19.0.dev0\n",
    "        !pip install --upgrade seaborn-image    \n",
    "        import seaborn_image as isns\n",
    "\n",
    "\n",
    "    try:\n",
    "        import xrft\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named xrft')\n",
    "        !pip install xrft \n",
    "        import xrft\n",
    "\n",
    "\n",
    "    NF = nap.read.NanonisFile(file)\n",
    "    Gr = nap.read.Grid(NF.fname)#\n",
    "    ## Gr 로  해당 grid data 불러옴 # 중간에 끊기면 안됨\n",
    "    channel_name = Gr.signals.keys()  # Gr 내의 data signals\n",
    "    #print (channel_name)\n",
    "    N = len(file);\n",
    "    f_name = file[0:N-4]\n",
    "    print (f_name) # Gr.basename\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    #Header part\n",
    "    #####################################\n",
    "    #  Gr.header\n",
    "    #####################################\n",
    "    [dim_px,dim_py] = Gr.header['dim_px'] \n",
    "    [cntr_x, cntr_y] = Gr.header['pos_xy']\n",
    "    [size_x,size_y] = Gr.header['size_xy']\n",
    "    [step_dx,step_dy] = [ size_x/dim_px, size_y/dim_py] \n",
    "    #pixel_size # size를 pixel로 나눔\n",
    "\n",
    "    ###   nX, nY --> x,y real scale  np array \n",
    "    nX = np.array([step_dx*(i+1/2) for i in range (0,dim_px)])# dimesion맞춘 xstep \n",
    "    nY = np.array([step_dy*(i+1/2) for i in range (0,dim_py)])# dimesion맞춘 ystep \n",
    "\n",
    "    x = cntr_x - size_x + nX\n",
    "    y = cntr_y - size_y + nY\n",
    "    # real XY position in nm scale, Center position & scan_szie + XY position\n",
    "    # center position  과 scan size을 고려한 x,y real \n",
    "    #####################################\n",
    "    # signal part\n",
    "    # Gr.signals\n",
    "    #####################################\n",
    "    topography = Gr.signals['topo']\n",
    "    params_v = Gr.signals['params'] \n",
    "    # params_v.shape = (dim_px,dim_py,15) \n",
    "    # 15: 3ds infos. \n",
    "    bias = Gr.signals['sweep_signal']\n",
    "    # check the shape (# of 'original' bias points)\n",
    "    I_fwd = Gr.signals['Current (A)'] # 3d set (dim_px,dim_py,bias)\n",
    "    I_bwd = Gr.signals['Current [bwd] (A)'] # I bwd\n",
    "    # sometimes, LI channel names are inconsistent depends on program ver. \n",
    "    # find 'LI Demod 1 X (A)'  or  'LI X 1 omega (A)'\n",
    "\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ])\n",
    "    # 'LI' & 'X' in  channel name (signal.keys) \n",
    "    LIX_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"X\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIX_fwd, LIX_bwd = Gr.signals[LIX_keys[0]] ,Gr.signals[LIX_keys[1] ]\n",
    "\n",
    "    # same for LIY\n",
    "    #print( [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ])\n",
    "    # 'LI' & 'Y' in  channel name (signal.keys) \n",
    "    LIY_keys = [s  for s in Gr.signals.keys()  if \"LI\"  in s  if \"Y\" in s ]\n",
    "    # 0 is fwd, 1 is bwd \n",
    "    LIY_fwd, LIY_bwd = Gr.signals[LIY_keys[0]] ,Gr.signals[LIY_keys[1] ]\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #plt.imshow(topography) # toppography check\n",
    "    #plt.imshow(I_fwd[:,:,0]) # LIX  check\n",
    "    ###########################################################\n",
    "\n",
    "    ##########################################################\n",
    "    #\t\t Grid data 에 대한 Title 지정 \n",
    "    #       grid size, pixel, bias condition 포함 #\n",
    "    #############################################################\n",
    "    # Gr.header.get('Bias>Bias (V)') # bias condition \n",
    "    # Gr.header.get('Z-Controller>Setpoint') # current set  condition\n",
    "    # Gr.header.get('dim_px')  # jpixel dimension \n",
    "    title = Gr.basename +' ('  + str(\n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep Start (V)'))\n",
    "    ) +' V ~ ' +str( \n",
    "        float(Gr.header.get('Bias Spectroscopy>Sweep End (V)'))\n",
    "    )+ ' V) \\n at Bias = '+ Gr.header.get(\n",
    "        'Bias>Bias (V)'\n",
    "    )[0:-3]+' mV, I_t =  ' + Gr.header.get(\n",
    "        'Z-Controller>Setpoint'\n",
    "    )[0:-4]+ ' pA, '+str(\n",
    "        Gr.header.get('dim_px')[0]\n",
    "    )+' x '+str(\n",
    "        Gr.header.get('dim_px')[1]\n",
    "    )+' points'\n",
    "    #############################################################       \n",
    "\n",
    "    ### some times the topography does not look right. \n",
    "    # * then use the reshaping function \n",
    "    # only for asymmetry grid data set\n",
    "\n",
    "    # eg) JW's MoS2 on HOPG exp. data \n",
    "\n",
    "    ###########################################################\n",
    "    # topography  를 topography_reshape 으로 재지정.  \n",
    "    ###########################################################\n",
    "    topo_dimension_true = True\n",
    "\n",
    "\n",
    "    if topo_dimension_true == True:\n",
    "        topography_reshape = topography   \n",
    "        #################################\n",
    "        I_fwd_copy = I_fwd\n",
    "        I_bwd_copy = I_bwd\n",
    "        LIX_fwd_copy = LIX_fwd \n",
    "        LIX_bwd_copy = LIX_bwd \t\n",
    "        # topography가 정상인 경우    \n",
    "        #################################\n",
    "\n",
    "        ##########################################################\n",
    "        # 예를 들어  #  MoS2 on HOPG image 는 \n",
    "        # 40 x 80 의 배열이 40x40 + 40 x40으로 되었음. \n",
    "        # x 한줄이 0-39: 1st line 40-79 : 2nd line임\n",
    "        # 0-40, 19-59, 39-79 가 set로 움직임. \n",
    "        # 세로로 40X80 배열을 만들어서 \n",
    "        # 0-39 를 2n으로 40-79 를 2n+1 으로 대입할것. \n",
    "        # topo # LIX f&b # I f&b #\n",
    "        ##########################################################\n",
    "\n",
    "    else: # topography가 비 정상인 경우  \n",
    "        # topo_dimension_true == False 일경우 \n",
    "        topography_reshape = np.transpose(np.copy(topography),(1,0)) \n",
    "        # 바꾼 dimension이 될 곳을 미리 만듬. \n",
    "        for x_indx, y_indx in enumerate (topography):\n",
    "        # print(x_indx) # 0-39 # print(y_indx.shape)\n",
    "            topography_reshape[2*x_indx,:] = y_indx[:40] # 앞쪽 절반은 첫번째줄로\n",
    "            topography_reshape[2*x_indx+1,:] = y_indx[40:80] # 뒷쪽 절반은 두번째 줄로  \n",
    "        #################################\n",
    "        # 새로 바꾸는 정렬 방법을 확인하여 같은방식으로 I, LIX 에도 적용\n",
    "        #################################\n",
    "        #제대로 붙었는지 테스트\n",
    "        plt.imshow(topography_reshape) # 80 * 40 OK\n",
    "        # topography_reshape 정렬 끝 \n",
    "        #################################\n",
    "        I_fwd_copy = np.transpose(np.copy(I_fwd),(1,0,2))\n",
    "        I_bwd_copy = np.transpose(np.copy(I_bwd),(1,0,2)) \n",
    "        # 바꾼 dimension이 될 곳을 미리 만듬. \t\n",
    "        for x_indx, yNbias_plane in enumerate (I_fwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            print(x_indx) # 0-39 \n",
    "            I_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            I_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로  \n",
    "\n",
    "        for x_indx, yNbias_plane in enumerate (I_bwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            print(x_indx) # 0-39 \n",
    "            I_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            I_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로plt.imshow(I_bwd_v[:,:,0]) # 40 * 256  cut \n",
    "        #################################\n",
    "        # I reshape is done \n",
    "        #################################\n",
    "        LIX_fwd_copy = np.transpose(np.copy(LIX_fwd),(1,0,2)) \n",
    "        LIX_bwd_copy = np.transpose(np.copy(LIX_bwd),(1,0,2)) \n",
    "        # 바꾼 dimension이 될 곳을 미리 만듬. \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_fwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            LIX_fwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            LIX_fwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로  \n",
    "        for x_indx, yNbias_plane in enumerate (LIX_bwd): \n",
    "            # 순서를바꿔서 두번째 index로 for loop\n",
    "            LIX_bwd_copy[2*x_indx,:,:] = yNbias_plane[:40,:] \n",
    "            # 앞쪽 절반은 첫번째줄로\n",
    "            LIX_bwd_copy[2*x_indx+1,:,:] = yNbias_plane[40:80,:] \n",
    "            # 뒷쪽 절반은 두번째 줄로\n",
    "        #################################\n",
    "        # LIX reshape is done \n",
    "        #################################\n",
    "    #제대로 붙었는지 테스트\n",
    "\n",
    "    #fig,axes = plt.subplots (nrows = 2,ncols = 3, figsize = (5,4),\n",
    "    #                         sharex=True, sharey=True)\n",
    "    #axs = axes.ravel()\n",
    "    #axs[0].imshow(topography)\n",
    "    #axs[0].set_title('topography')\n",
    "\n",
    "    #axs[1].imshow(I_fwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[1].set_title('I_fwd[0]')\n",
    "    #axs[2].imshow(LIX_fwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[2].set_title('LIX_fwd[0]')\n",
    "\n",
    "    #axs[3].imshow(topography_reshape)\n",
    "    #axs[3].set_title('topo_reshape')\n",
    "\n",
    "    #axs[4].imshow(I_bwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[4].set_title('I_bwd[0]')\n",
    "\n",
    "    #axs[5].imshow(LIX_bwd_copy[:,:,0]) # 80 * 40 OK\n",
    "    #axs[5].set_title('LIX_bwd[0]')\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # after reshaping \n",
    "\n",
    "    topography = topography_reshape \n",
    "    #################################\n",
    "    I_fwd = I_fwd_copy \n",
    "    I_bwd = I_bwd_copy \n",
    "    LIX_fwd  = LIX_fwd_copy \n",
    "    LIX_bwd  = LIX_bwd_copy\n",
    "    ##########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # Bias segment check      #\n",
    "    ###########################\n",
    "    Segment = Gr.header['Bias>Bias (V)']\n",
    "    # bias unit : '(V)' \n",
    "\n",
    "    if type(Segment) == str: # single segment case\n",
    "        print ('No Segments\\n'+ 'Grid data acquired at bias = '+  str(float(Segment)) + 'V')    \n",
    "    ## No Segments # +  bias setting \n",
    "\n",
    "    ########################\n",
    "    # bias interpolation to have bias \n",
    "    # bias_mV 는 bias 를 0 포함한 값으로interploation \n",
    "    # 3D data 가운데 x,y 를 꺼내서 bias interpolation \n",
    "    # e.g  256--> 양 끝점을 포함한 256+1 으로. (center 가 0가 되도록 )\n",
    "        if len(bias)%2==0:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias)+1)) \n",
    "            # 시작 부터 끝까지, 0포함 홀수, 전체크기+1 개의 단계로 세분화\n",
    "        else:\n",
    "            bias_new = np.linspace(bias[0],bias[-1],num=(len(bias))) \n",
    "            # bias_new  는 간격이 홀수개가 되도록 나눈 것임, 즉 0에가장 가까운 값이 하나뿐이도록 조정함 \n",
    "        #새로 만든 bias_new 안에 있는지 없는지를 찾는다. \n",
    "        # '''    if np.amin(abs(bias_new)) < 1E-3: \n",
    "        ## 즉 0 이 아닌 값이 나오는 경우 이부분이 if가 필요한지 의문 ''' \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # 0  에 가장가까운 값이 나온 곳의 index 를 찾음 \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # 가장 0에 가까운 값을 0으로 옮겼으니 항상 0 를 포함함. \n",
    "        #bias_new[np.where(bias_new == np.amin(abs(bias_new)))]=0\n",
    "\n",
    "    ##############################################\n",
    "    #'Segment Start (V), Segment End (V), Settling (s), Integration (s), Steps (xn)'\n",
    "    elif len(Segment) == 3:\n",
    "        print('Number of Segments =' + str(len(Segment))) \n",
    "        Segments = np.array([[ float(Segments) \n",
    "                              for Segments in Seg.split(',') ] \n",
    "                             for Seg in Segment], dtype = np.float64)\n",
    "        #  Segment 에서 한줄 씰 꺼내서, array, 한줄씩\n",
    "        #','로 split한 문자들을 하나씩 float 변수로 바꿈, & np array화\n",
    "        ### 현재 Nanonis version에서 bias 는 정확한 값이 아님. \n",
    "        Seg1 = np.linspace(Segments[0,0],Segments[0,1],int(Segments[0,-1]))\n",
    "        Seg2 = np.linspace(Segments[1,0],Segments[1,1],int(Segments[1,-1]))\n",
    "        Seg3 = np.linspace(Segments[2,0],Segments[2,1],int(Segments[2,-1]))\n",
    "        # 겹치는  boundary 제외하고([1:]), Seg1, Seg2[1:], Seg3[1:] 합친다. \n",
    "        bias_Seg = np.append(np.append(Seg1,Seg2[1:]),Seg3[1:]) \n",
    "        # Seg1 에 Seg2[1:] 더하고, 거기에 다시한번 Se3[1:] 더함\n",
    "        print ('bias_Seg size = ' + str(len(bias_Seg)))\n",
    "        bias_Nsteps=int(int(Segments[1,-1])/\n",
    "                        (Seg2[-1]-Seg2[0])*(bias_Seg[-1]-bias_Seg[0]))\n",
    "        # 새로운 bias step 은 가장 작은 step size를 전체 영역에 적용함.    \n",
    "        bias_Nsteps_size = (Seg2[-1]-Seg2[0])/(Segments[1,-1])\n",
    "        # (Segments[1,0]-Segments[1,1])/int(Segments[1,-1]) # bias step size    \n",
    "        Neg_bias=-1*np.arange(\n",
    "            0,bias_Nsteps_size*bias_Nsteps/2, bias_Nsteps_size)\n",
    "        Pos_bias=np.flip(\n",
    "            np.arange(0,bias_Nsteps_size*bias_Nsteps/2,bias_Nsteps_size))\n",
    "        bias_new = np.flip( np.append(Pos_bias,Neg_bias[1:])) \n",
    "        # segment 이후 bias 는 bias_new 로 재조립되었음\t\n",
    "        #여기에서 bias_new 를 홀수로 변환\n",
    "        if len(bias_new)%2==0:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new)+1)) \n",
    "        else:\n",
    "            bias_new = np.linspace(bias_new[0],bias_new[-1],num=(len(bias_new))) \n",
    "        # 여기서 다시 bias_new가 0를 포함하는 확인해야함. \n",
    "        nearest_zero_bias = np.where(abs(bias_new) == np.amin(abs(bias_new))) \n",
    "        # 0  에 가장가까운 값이 나온 곳의 index 를 찾음 \n",
    "        bias_new = bias_new - bias_new[nearest_zero_bias] \n",
    "        # 시작 부터 끝까지, 0포함 홀수\n",
    "        print ('bias_new size = ' + str(len(bias_new)))\n",
    "        # bias \n",
    "    # make a new list for Bias\n",
    "    else:\n",
    "        print (\"Segment error /n code a 5 Sements case\")\n",
    "    #\n",
    "    ######################################################################\n",
    "    # Segment가 있더라도 모두 \n",
    "    # 0을 포함한 홀수개의 같은 간격을 갖는  bias_new 로 bias 축을 바꿨음. \n",
    "    ######################################################################\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # bias_new 를 이용해서 interpolation\n",
    "    # I_fwd, I_bwd, LIX_fwd, LIX_bwd\n",
    "    # => I_fwd_interpolate\n",
    "    #######################################################################\n",
    "\n",
    "    def sweep_interpolation(np3Ddata, bias, bias_new):\n",
    "        np3Ddata_interpolate = np.empty(\n",
    "                    (np3Ddata.shape[0],np3Ddata.shape[1],bias_new.shape[0])) \n",
    "        # 원래값과 같지만, bias_new의 형태를 갖춘 empty interpolate 영역 만들고\n",
    "        #xy dim 은 그대로 z 는 new bias dim으로        \n",
    "        for x_i,np3Ddata_xi in enumerate(np3Ddata):\n",
    "            for y_j,np3Ddata_xi_yj in enumerate(np3Ddata_xi):\n",
    "                #print (np3Ddata_xi_yj.shape)\n",
    "                Interpolation1D_i_f = sp.interpolate.interp1d(\n",
    "                    bias,\n",
    "                    np3Ddata_xi_yj,\n",
    "                    fill_value = \"extrapolate\",\n",
    "                    kind = 'cubic')\n",
    "                np3Ddata_interpolate[x_i,y_j,:] = Interpolation1D_i_f(bias_new)\n",
    "        return np3Ddata_interpolate\n",
    "\n",
    "    I_fwd_interpolate = sweep_interpolation (I_fwd, bias, bias_new)\n",
    "    I_bwd_interpolate = sweep_interpolation (I_bwd, bias, bias_new)\n",
    "    LIX_fwd_interpolate = sweep_interpolation (LIX_fwd, bias, bias_new)\n",
    "    LIX_bwd_interpolate = sweep_interpolation (LIX_bwd, bias, bias_new)\n",
    "\n",
    "    ####################################################\n",
    "    # interpolation 값과 bias_new 를 \n",
    "    #\n",
    "    # bias 방향 바꿈 그림 그릴때 헷갈리지 않도록. \n",
    "    ###################################################\n",
    "    # Bias원래 방향에 맞춰서 둘중하나 선택 \n",
    "    ###################################################\n",
    "    if bias[0]>bias[-1]: \n",
    "        # 시작점이 마지막점보다 크면 (양수에서시작)\n",
    "        # 변하는 것 없음. \t\n",
    "        print ('start from POS bias')\n",
    "        I_fwd = I_fwd_interpolate\n",
    "        I_bwd = I_bwd_interpolate\n",
    "        LIX_fwd = LIX_fwd_interpolate\n",
    "        LIX_bwd = LIX_bwd_interpolate\n",
    "        bias_mV = bias_new*1000\n",
    "    else:  # 시작점이 마지막점보다 작으면 (음수에서시작)\n",
    "        print ('start from NEG bias')\n",
    "        I_fwd = np.flip(I_fwd_interpolate,2)\n",
    "        I_bwd = np.flip(I_bwd_interpolate,2)\n",
    "        LIX_fwd = np.flip(LIX_fwd_interpolate,2)\n",
    "        LIX_bwd = np.flip(LIX_bwd_interpolate,2)\n",
    "        bias_new_flip = np.flip(bias_new)\n",
    "        # bias 0 는 POS , bias last 는 NEG bias로 바꿈. \n",
    "        bias_mV = bias_new_flip*1000\n",
    "        print ('Flip => start from POS bias')\n",
    "    ####################################################\n",
    "\n",
    "    ###################################################\n",
    "    # convert data XR DataSEt\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    grid_xr = xr.Dataset(\n",
    "        {\n",
    "            \"I_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_fwd),\n",
    "            \"I_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], I_bwd),\n",
    "            \"LIX_fwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_fwd),\n",
    "            \"LIX_bwd\" : ([\"Y\",\"X\",\"bias_mV\"], LIX_bwd),\n",
    "            \"topography\" : ([\"Y\",\"X\"], topography)\n",
    "        },\n",
    "        coords = {\n",
    "            \"X\": ([\"X\"], x),\n",
    "            \"Y\": ([\"Y\"], y),\n",
    "            \"bias_mV\": ([\"bias_mV\"], bias_mV)\n",
    "        }\n",
    "    )\n",
    "    grid_xr.attrs[\"title\"] = title\n",
    "    #grid_xr.attrs['image_size'] = \n",
    "    #grid_xr.attrs['samlpe'] = \n",
    "    \n",
    "    grid_xr.attrs['image_size']= [size_x,size_y]\n",
    "    grid_xr.attrs['X_spacing']= step_dx\n",
    "    grid_xr.attrs['Y_spacing']= step_dy    \n",
    "    #grid_xr.attrs['freq_X_spacing']= 1/step_dx\n",
    "    #grid_xr.attrs['freq_Y_spacing']= 1/step_dy\n",
    "\n",
    "    # in case of real X Y ( center & size of XY)\n",
    "    if center_offset == True:\n",
    "        # move the scan center postion in real scanner field of view\n",
    "        grid_xr.assign_coords( X = (grid_xr.X + cntr_x -  size_x/2))\n",
    "        grid_xr.assign_coords( Y = (grid_xr.Y + cntr_y -  size_y/2))\n",
    "    else :\n",
    "        pass\n",
    "        # (0,0) is the origin of image \n",
    "    \n",
    "    return grid_xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be2a85-0583-497c-9e73-6d9aad7a95d8",
   "metadata": {},
   "source": [
    "# <font color=blue>gwy_image2df & gwy_df_channel2xr</font>\n",
    "## 4. Gwyddion 2D image to PANDAS Dataframe or Xarray\n",
    "### 4.1. **gwy_image2df** : gwy file name $\\to$ PANDAS DataFrame\n",
    "* input: *.gwy file \n",
    "* output: PANDAS DataFrame\n",
    "    * gwyddion 2D image data (*gwy)  $\\to $ numpy $\\to$ pd.DataFrame(_df) \n",
    "\n",
    "### 4.2. **gwy_df_channel2xr** : Choose a data channe in gwy_df $\\to$ Xarray DataArray\n",
    "* input: gwy_df dataframe & channel number ( N=0)\n",
    "* output: Xarray DataSet \n",
    "    * pd.DataFrame(_df)  $\\to $ xarray Dataset (_xr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fb4183-6850-4d0c-835c-670a2dd58393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gwy_image2df (gwy_file_name):\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        import gwyfile\n",
    "    except ModuleNotFoundError:\n",
    "        warn('ModuleNotFoundError: No module named gwyfile')\n",
    "        !pip install gwyfile\n",
    "        import gwyfile\n",
    "    gwyfile_df = pd.DataFrame(gwyfile.util.get_datafields(gwyfile.load(gwy_file_name)))\n",
    "    # convert all gwy file channels to pd.DataFrame\n",
    "    pd.set_option('display.float_format', '{:.3e}'.format)\n",
    "    return gwyfile_df\n",
    "\n",
    "#gwy_df = gwyImage2df( file_list_df.file_name[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37e9d92-6f6d-4f1c-8041-10700dbf6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gwy_df_channel2xr (gwy_df, ch_N=0): \n",
    "    import pandas as pd\n",
    "    #convert a channel data to xr DataArray format\n",
    "    chN_df = gwy_df.iloc[:,ch_N]\n",
    "    chNdf_temp = pd.DataFrame(chN_df.data.reshape((chN_df.yres, chN_df.xres))).stack()\n",
    "    chNdf_temp = chNdf_temp.rename_axis (['Y','X'])\n",
    "    x_step = chN_df.xreal / chN_df.xres \n",
    "    y_step = chN_df.yreal / chN_df.yres \n",
    "    chNxr = chNdf_temp.to_xarray()\n",
    "    chNxr = chNxr.assign_coords(X = chNxr.X.values * x_step, \n",
    "                                Y = chNxr.Y.values * y_step )\n",
    "    return chNxr\n",
    "\n",
    "# gwy_ch_xr = gwy_df_channel2xr(gwy_df, ch_N=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2349799",
   "metadata": {
    "incorrectly_encoded_metadata": "jp-MarkdownHeadingCollapsed=true",
    "lines_to_next_cell": 0,
    "tags": []
   },
   "source": [
    "# updated 2021 0607\n",
    "\n",
    "##  * To Be Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a55547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
